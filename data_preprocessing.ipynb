{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "090f834a-68ac-4af9-9e09-817e28f15623",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 목포부주초 Wave1_6-5(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 송수초 Wave1_4-1 (학생)(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 송수초 Wave1_4-3 (학생)(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 송수초 Wave1_4-4 (학생)(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 송수초 Wave1_5-2 (학생)(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 송수초 Wave1_5-4(학생)(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 송수초 Wave1_5-5 (학생)(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 송수초 Wave1_6-5 (학생)(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 하원초 Wave1_4-1(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 하원초 Wave1_4-2(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 하원초 Wave1_4-3(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 하원초 Wave1_5-1(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 하원초 Wave1_5-2(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 하원초 Wave1_5-3(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 하원초 Wave1_5-4(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 하원초 Wave1_6-1(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 하원초 Wave1_6-2(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 하원초 Wave1_6-3(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 하원초 Wave1_6-4(응답).xlsx\n",
      "C:\\Users\\qndba\\peer\\현장데이터\\2024 송수초 Wave1_6-2 (학생)(응답).xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. 현장데이터 폴더 경로 지정\n",
    "base_path = Path(r\"C:\\Users\\qndba\\peer\\현장데이터\")\n",
    "\n",
    "# 2. 'wave'로 시작하고 .xlsx 확장자인 파일 모두 찾기\n",
    "excel_files = list(base_path.rglob(\"*wave*.xlsx\"))\n",
    "\n",
    "# 3. 데이터프레임을 담을 리스트\n",
    "dfs = []\n",
    "\n",
    "# 4. 각 엑셀에서 '설문지 응답 시트1' 시트를 읽어오기\n",
    "for file in excel_files:\n",
    "    try:\n",
    "        print(file)\n",
    "        df = pd.read_excel(file, sheet_name='설문지 응답 시트1', engine='openpyxl')\n",
    "        df['source_file'] = file.name  # 출처 파일명 기록\n",
    "        dfs.append(df)\n",
    "    except Exception as e:\n",
    "        print(f\"파일 {file.name} 에서 오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7969d5f3-1a30-47d1-9035-084ac29cf160",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['51강*욱', '52곽*중', '53김*재', '54김*은', '55김*우', '56김*홍', '57김*윤', '58박*형', '59박*린', '510박*우', '511박*유', '512배*을', '513서*웅', '514오*서', '516이*영', '517이*', '518*훈', '519장*준', '520장*수', '521정***타', '522조*민', '523진*랑', '524최*원', '525최*예', '526홍*경']\n",
      "['강민하', '고강민', '김무성', '김성빈', '김성윤', '박지후', '서도현', '손정우', '오은율', '이유준', '이한', '정민준', '정준휘', '한정우', '김가영', '김서영', '김서현', '김소율', '김채아', '김태연', '문하율', '문하음', '서지현', '정세윤', '조윤채', '최소은', '최시아']\n",
      "['김관우', '김병하', '김태훈', '남윤우', '신원재', '윤대웅', '이범준', '이준서', '장지욱', '정해람', '조예준', '홍종빈', '황규진', '강주은', '고나은', '김나현', '김다혜', '김서하', '김세연', '밀라드아리아로빈은유', '박여울', '변서유', '송유안', '이하린', '정라원', '정은우', '한서연']\n",
      "['강영재', '김도윤', '김서준', '김서진', '김주원', '김지한', '김하랑', '손호진', '이승유', '이승주', '정재준', '조영원', '홍주현', '조민성', '강민지', '김서현', '김시호', '남유진', '안소율', '양라빈', '유연우', '윤희진', '이수아', '이지우', '조은우', '표윤희', '허은수']\n",
      "['강윤우', '김정진', '김채우', '김한겸', '박지성', '백동우', '백준우', '이동건', '임지원', '표재민', '홍주원', '강보민', '김라은', '김민서', '김태린', '박지아', '예지우', '오예진', '이서현', '정예슬', '최연우', '하지민', '한예주', '허수빈']\n",
      "['강우진', '김승윤', '안태현', '옥준우', '왕찬우', '이규현', '이승현', '이지환', '정민형', '최주환', '최준혁', '강다연', '김민서', '박세연', '배희주', '성하윤', '안서연', '엽지원', '이정인', '이혜원', '임윤서', '최은서', '하민경', '홍윤지']\n",
      "['강율', '고도윤', '김강민', '김민준', '김서준', '김서진', '김휘수', '박제희', '이준서', '이창현', '정승하', '권가온', '김지유', '김태희', '맹성리', '박규리', '배서현', '양은서', '오윤', '유민아', '이수연', '정리은', '조아인', '최수빈']\n",
      "['김동영', '김준경', '박건형', '이민형', '이서원', '이재서', '정우진', '조동규', '진유환', '천재원', '최승우', '최우준', '현가원', '김민호', '김경현', '김은송', '김태은', '송예모', '안유진', '이나연', '이다은', '이채영', '이채원', '장하윤', '현라원']\n",
      "['11강*서', '12강*진', '13고*랑', '14공*경', '15김*우', '16박*윤', '17박*준', '18박*민', '19박*율', '110배*호', '111선*빈', '112송*민', '113송*빈', '114신*원', '115양*희', '116엄*민', '117이*연', '118이*현', '119이*경', '120이*명', '121이*섭', '122임*환', '123전*준', '124최*림', '125한*은']\n",
      "['21강*성', '22김*빈', '23김*율', '24김*완', '25김*준', '26김*우', '27김*원', '28김*윤', '29남*혜', '210문*연', '211박*나', '212서율', '213서*후', '214송*우', '215신*화', '216엄*연', '217오*겸', '218이*현', '219이*윤', '220임*민', '221장*준', '222채*우', '223최*윤', '224최*인', '225홍*지']\n",
      "['31강*아', '32김*경', '33김*서', '34김*윤', '35김*준', '36김*윤', '37민*윤', '38박*은', '39박*윤', '310서*무', '311선*빈', '312오*우', '313유*혁', '314은*민', '315이*윤', '316이*홍', '317이*찬', '318이*용', '319이*수', '320이*호', '321장*은', '322장*진', '323채*성', '324최*준', '325최*종', '326한*서']\n",
      "['11강*혁', '12권*율', '13김*현', '14김*림', '15김*랑', '16김*경', '17남*환', '18박*선', '19박*우', '110박*우', '111박*윤', '112성*민', '113신*율', '114이*빈', '115이*희', '116이*신', '117임*원', '118장*슬', '119정*유', '120홍*서', '121홍*나']\n",
      "['21강*람', '22권*호', '23김*민', '24김*율', '25김*서', '26김*혁', '27박*을', '28박*연', '29박*영', '210원*현', '211이*윤', '212이*영', '213이*준', '214이*아', '215정*은', '216정*현', '217조*준', '218최*현', '219최*유', '220홍*주']\n",
      "['31강*원', '32공*윤', '33김*린', '34김*연', '35김*현', '36노*윤', '37박*현', '38박*진', '39박*민', '310서*은', '311송*연', '312신*율', '313윤*희', '314이*주', '315이*유', '316이*윤', '317이*은', '318전*빈', '319주*환', '320임*연']\n",
      "['41구*진', '41구*진', '42권*서', '43권*하', '44김*서', '45김*지', '46김*준', '48김*결', '49박*늘', '410심*지', '411양*윤', '412유*아', '413이*준', '414이*준', '415이*연', '416이*윤', '417장*서', '418전*훈', '419전*원', '420정*우']\n",
      "['11김*빈', '12김*서', '13김*재', '14김*하', '15김*원', '16김*은', '17김*서', '18김*준', '19명*우', '110박*원', '111박*윤', '112박*우', '113변*은', '114석*우', '115송*양', '116신*인', '117용*희', '118이*아', '119이*준', '120이*아', '120이*아', '122이*빈']\n",
      "['21강*아', '22기*서', '23김*은', '24김*정', '25문*은', '26문*별', '27문*리', '28박*영', '29박*원', '210송*솔', '211엄*린', '212윤*은', '213이*준', '214이*아', '215이*서', '216이*아', '217정*희', '218주*경', '219최*준', '220최*윤', '221현*민']\n",
      "['31강*원', '32곽*호', '33김*준', '34김*희', '35김*인', '36박*설', '37박*민', '38서*결', '39손*성', '310송*진', '311양*현', '312유*연', '313윤*성', '314이*원', '315이*랑', '316이*린', '317임*화', '318정*은', '319차*서', '320황*연']\n",
      "['41강*원', '42권*연', '43김*담', '44김*완', '45김*주', '46문*진', '47박*서', '48박*주', '49배*', '410서*호', '411손*원', '412송*우', '413신*은', '414안*민', '415이*희', '416이*은', '417이*준', '418장*우', '419전*준', '420제*훈', '421조*윤']\n",
      "['강기태', '권휘준', '김태현', '박승유', '박호윤', '송윤호', '아윤재', '우상진', '유태경', '이경보', '이준성', '조이현', '최지호', '홍재원', '임태이', '강서윤', '김규리', '김세원', '노지안', '류채원', '박시은', '박아현', '이수현', '장하윤', '조자은']\n"
     ]
    }
   ],
   "source": [
    "personinfo_df = df.loc[:,['타임스탬프', '학년', '반', '번호', '성별', '이름']]\n",
    "keywords = [\n",
    "    \"가장 인기가 있는\",\n",
    "    \"가장 친한 친구는?\",\n",
    "    \"학급에서 영향력이 있\",\n",
    "    \"친구들의 생각을 자주\",\n",
    "    \"험담을 하거나 다른 친\",\n",
    "    \"나쁜 소문을 퍼뜨리는\",\n",
    "    \"친절한\",\n",
    "    \"협력적인\"\n",
    "]\n",
    "\n",
    "# 전체 dfs 처리 결과를 담을 리트트\n",
    "all_item_matrix_dicts = []\n",
    "\n",
    "for i, df in enumerate(dfs): # i가 각 학급 순서를 의미함\n",
    "    filtered_cols = [col for col in df.columns if any(keyword in col for keyword in keywords)]\n",
    "    filtered_df = df[filtered_cols]\n",
    "    personinfo_df = df.iloc[:,:6]\n",
    "    row_df = pd.concat([personinfo_df, filtered_df], ignore_index=False, axis=1)\n",
    "    \n",
    "    # 전처리된거에서 인적정보 다시 분리\n",
    "    rowinfo_df = row_df.iloc[:,:6]\n",
    "    print(rowinfo_df['이름'].tolist())\n",
    "\n",
    "    # 아이템 분리 후\n",
    "    rowitem_df = row_df.iloc[:,6:]\n",
    "    # 문항별로 또 분리\n",
    "    keywords_dict = {\n",
    "        'PN1': \"가장 인기가 있는\",\n",
    "        'PN14': \"가장 친한 친구는?\",\n",
    "        'PN4': \"학급에서 영향력이 있\",\n",
    "        'PN5': \"친구들의 생각을 자주\",\n",
    "        'PN6': \"험담을 하거나 다른 친\",\n",
    "        'PN7': \"나쁜 소문을 퍼뜨리는\",\n",
    "        'PN8': \"친절한\",\n",
    "        'PN9': \"협력적인\"\n",
    "    }\n",
    "    # 문항별 데이터프레임을 담을 딕셔너리\n",
    "    item_matrix_dict = {}\n",
    "    # keywords_dict에 따라 필터링된 데이터프레임을 저장\n",
    "    for item_no, keyword in keywords_dict.items():\n",
    "        temp_df = rowitem_df.filter(regex=keyword)\n",
    "        temp_df = temp_df.fillna(0)\n",
    "        labels = rowinfo_df['이름'].tolist()\n",
    "        temp_df.index = labels\n",
    "        temp_df.columns = labels\n",
    "        item_matrix_dict[item_no] = temp_df # 문항 하나에 해당 응답 df 저장\n",
    "        \n",
    "    # i의 순서 학급에 문항별 응답 df가 저장된 딕셔너리\n",
    "    all_item_matrix_dicts.append(item_matrix_dict)\n",
    "\n",
    "    all_triplets = []\n",
    "\n",
    "    for item_no, item_df in item_matrix_dict.items():\n",
    "        idx_pairs = item_df.where(item_df == 1).stack().index.tolist() # 이 코드 공부하기#############\n",
    "        for r, c in idx_pairs:\n",
    "            all_triplets.append({'point_item_no': item_no, 'student_designation': r, 'student_nomination': c})\n",
    "        triplet_df = pd.DataFrame(all_triplets)\n",
    "    triplet_df.to_csv(f'C:/Users/qndba/peer/현장데이터/class_{i+1}.csv', encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6dc24d-8076-4117-9e29-068f9214d440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
